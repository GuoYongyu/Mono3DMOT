# Mono3DMOT
1. 【已解决】我现在应该把定位的代码写到哪里？单独写个文件还是直接在原来的上改
    - 我觉得但写个函数比较好，之后需要搞明白的是在哪里调用

2. 【不可行，采集到了灰度视频】把那个indemind摄像头用起来，采集图片？
    - 先搞清楚哪几个参数不知道，以及后续有没有可能知道？
    - 如果没有可能知道，这种方法求实际的物体空间位置，是徒劳的
    - 经过一番调研，感光原件的大小也知道了，可以操作一番看下效果

3. 【当前】现在主要的问题是什么？如何推进下一步工作？
    0. 提出了一个解决方案，当然这个方案很简单
    1. 验证我的方法的效果，如何验证？KITTI是可能的方案
        - 效果好可以着手写论文；很多事情是边写边做
    2. 三维可视化可以先做？写论文、做系统，都需要可视化效果
        - 可视化单张图片是做到了--在jupyter notebook实现
        - 从单张图片，如何形成视频？真正的动画效果，这是我想看到的
            - 有了一个想法就是放在循环里，不可行；会打印多幅图片，而不是形成视频
        - 为了可视化方便，可能需要把 results.txt 写成 results.json? 每个frame是其中一个item
    3. 尝试了几种方法，根据相机成像模型得到行人位置，是一种解决方案，但是评估起来很困难
        - 都失败了，是不是思路没有走上正轨，换换思路 --> 方法？
        - 【已解决】评估的时候，FairMoT的输入是视频，我现在要验证图片，这是一个比较棘手的问题
            - 评估了两张图片，效果看起来不错
    4. 开始写作，朝哪个主题写？
            - 和老师讨论，老师的建议是：一种快速的多目标3D定位跟踪方法；3D这块强行画框？？
            - 录个视频，看效果，我也正有此意
            - 老师说下载KITTI数据集，肯定是给我用的，实验部分这么搞？
            - 调研一下画3D图的工具
    5. 三维可视化是写论文的一个亮点
    6. 训练是在那6个数据集上，再在上面测试就不行了吧；所以要选新的数据集
        - KITTI，主要验证定位效果，计算误差率还是准确率？我目前是在training data上做的实验，是不是应该更改到测试集，提交结果到服务器？
            - 不知道KITTI object <测试集>能不能单独评估3D定位结果，或者能不能评估2D检测+3D定位结果，这就需要做实验了
            - 模型没在KITTI上训练，所以在KITTI training data上评估，没有毛病
        - 2D MOT 2015, MOT16, MOT17, MOT20 这几个都下载下来？在它们的测试集做实验，搞清楚各个指标什么意思
        - 下午该和老师讨论一波了：
            1. 实验部分用不用和其他方法对比，参照其他论文结果？？ 
            2. 让老师帮下数据集 
            3. 提交结果，注册时要输入导师邮箱
    7. 现在的工作该从哪里做起？
        - 我觉得是要完善实验部分，把数据记下来，看看怎么画图画表
            - 问题是我只有自己的结果，没有别人方法的结果，借鉴fairmot里面对比的方法
            - 对于目前的实验，还有什么要充实的部分？
        - 把图表贴上去，开始写文字，分析一些结果
            - 表画出来了，只有自己的结果，这样没办法分析
        - 再写相关工作，实验部分添加相关工作
            - 种种迹象表明，该写相关工作的内容、加相关工作的实验了
            - 相关工作写了，就要对比吧
        - 完善introduction

4. 【可以尝试】或许直接研究一下Kitti数据集？看它能不能帮解决这个问题
    - 大家做实验，基本避不开KITTI
    - 下载数据之前，搞清楚整体结构，以及每个模块的关系；现在基本搞清楚了，从文档来看，大部分问题得到
    - 仔细想了一下，KITTI数据集没有提供相机感光原件尺寸大小，我的方法提供不了准确的结果？
